{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50f7f68",
   "metadata": {},
   "source": [
    "# Pocking at Ever Larger Language Models\n",
    "## An introduction for (digital) humanists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f8ef1",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9047ad",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e1e05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-26 17:01:10--  https://bl.iro.bl.uk/downloads/59a8c52f-e0a5-4432-9897-0db8c067627c\n",
      "Resolving bl.iro.bl.uk (bl.iro.bl.uk)... 52.211.187.46, 52.209.26.210, 18.202.144.94\n",
      "Connecting to bl.iro.bl.uk (bl.iro.bl.uk)|52.211.187.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 144694 (141K) [application/zip]\n",
      "Saving to: ‘animacy.zip’\n",
      "\n",
      "animacy.zip         100%[===================>] 141.30K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2023-04-26 17:01:10 (2.77 MB/s) - ‘animacy.zip’ saved [144694/144694]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O animacy.zip https://bl.iro.bl.uk/downloads/59a8c52f-e0a5-4432-9897-0db8c067627c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc175be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -O requirements.txt https://raw.githubusercontent.com/kasparvonbeelen/SAS-LLM-Worshop/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6ad00bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.29.0)\n",
      "Requirement already satisfied: transformers in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (4.28.1)\n",
      "Requirement already satisfied: torch in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.15.1)\n",
      "Requirement already satisfied: torchaudio in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: pandas in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (2.0.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.1-cp39-cp39-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 3)) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 3)) (2023.3.23)\n",
      "Requirement already satisfied: filelock in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 3)) (3.12.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 3)) (0.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from torch->-r requirements.txt (line 4)) (3.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from torch->-r requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: jinja2 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from torch->-r requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from torch->-r requirements.txt (line 4)) (1.11.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 5)) (9.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 7)) (2023.3)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-macosx_11_0_arm64.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: fsspec in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->-r requirements.txt (line 3)) (2023.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 8)) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from sympy->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.3 importlib-resources-5.12.0 kiwisolver-1.4.4 matplotlib-3.7.1 pyparsing-3.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01edb9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  animacy.zip\r\n",
      "  inflating: animacy_data/LwM-nlp-animacy-annotations-machines19thC.tsv  \r\n",
      "  inflating: animacy_data/read-me    \r\n"
     ]
    }
   ],
   "source": [
    "!unzip animacy.zip -d animacy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eae787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE            SAS-Workshop.ipynb \u001b[34manimacy_data\u001b[m\u001b[m\r\n",
      "README.md          animacy.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd4cdf",
   "metadata": {},
   "source": [
    "## From mini to somewhat larger\n",
    "\n",
    "... but not large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01583dcb",
   "metadata": {},
   "source": [
    "Statistical Language Model\n",
    "\n",
    "Predict and sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1d8f8",
   "metadata": {},
   "source": [
    "### A Shakespeare language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd11e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c975a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('https://www.gutenberg.org/cache/epub/100/pg100.txt').text.lower().strip()\n",
    "text = requests.get('https://programminghistorian.org/assets/interrogating-national-narrative-gpt/articles.txt').text.lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "62391272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"uk opposition parties have agreed not to back boris johnson's demand for a general election before t\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eb8c1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('\\w+')\n",
    "tokens = pattern.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "841f0a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uk', 'opposition', 'parties', 'have', 'agreed', 'not', 'to', 'back', 'boris', 'johnson', 's', 'demand', 'for', 'a', 'general', 'election', 'before', 'the', 'eu', 'summit', 'in', 'mid', 'october', 'labour', 'the', 'lib', 'dems', 'the', 'snp', 'and', 'plaid', 'cymru', 'say', 'they', 'will', 'vote', 'against', 'the', 'government', 'or', 'abstain', 'in', 'monday', 's', 'vote', 'on', 'whether', 'to', 'hold', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "04a8e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(tokens: list,n: int=2):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        text\n",
    "        n\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens))]\n",
    "\n",
    "bigrams = ngrams(tokens,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "624c8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uk opposition',\n",
       " 'opposition parties',\n",
       " 'parties have',\n",
       " 'have agreed',\n",
       " 'agreed not',\n",
       " 'not to',\n",
       " 'to back',\n",
       " 'back boris',\n",
       " 'boris johnson',\n",
       " 'johnson s']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cf202708",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "76cbdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = Counter(ngrams(tokens,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "42e5f026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the prime minister', 5227),\n",
       " ('a no deal', 3301),\n",
       " ('with the eu', 2890),\n",
       " ('no deal brexit', 2392),\n",
       " ('the uk s', 2001),\n",
       " ('the european union', 1983),\n",
       " ('of the eu', 1886),\n",
       " ('leave the eu', 1811),\n",
       " ('the eu s', 1679),\n",
       " ('to leave the', 1657)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3170630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tetragram = Counter(ngrams(tokens,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b57f90a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a no deal brexit', 2133),\n",
       " ('to leave the eu', 1168),\n",
       " ('the prime minister s', 1075),\n",
       " ('the house of commons', 888),\n",
       " ('last modified on mon', 866),\n",
       " ('modified on mon 3', 860),\n",
       " ('on mon 3 feb', 860),\n",
       " ('mon 3 feb 2020', 860),\n",
       " ('the rest of the', 676),\n",
       " ('of a no deal', 634)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tetragram.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "37ee74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39922"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(tokens)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "62c445d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence = 'the duke of'\n",
    "sequence = 'a no deal'\n",
    "prob_next_word = Counter({w: tetragram[f'{sequence} {w}'] / trigrams[sequence] for w in vocabulary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "df091a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brexit', 0.64616782793093),\n",
       " ('exit', 0.07906694940926992),\n",
       " ('scenario', 0.06846410178733717),\n",
       " ('outcome', 0.028476219327476522),\n",
       " ('departure', 0.016964556195092396),\n",
       " ('and', 0.0069675855801272345),\n",
       " ('the', 0.006664647076643442),\n",
       " ('situation', 0.005755831566192063),\n",
       " ('would', 0.005755831566192063),\n",
       " ('or', 0.00545289306270827),\n",
       " ('split', 0.004847016055740685),\n",
       " ('crash', 0.004241139048773099),\n",
       " ('he', 0.004241139048773099),\n",
       " ('is', 0.003938200545289306),\n",
       " ('on', 0.003938200545289306),\n",
       " ('but', 0.0036352620418055137),\n",
       " ('in', 0.003332323538321721),\n",
       " ('it', 0.003332323538321721),\n",
       " ('divorce', 0.003332323538321721),\n",
       " ('withdrawal', 0.002726446531354135)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_next_word.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fc657e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = pd.DataFrame(list(prob_next_word.most_common(20)),columns=['token','prob'])\n",
    "df_prob.index = list(df_prob[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6113d2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'probability of next word'}>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_prob.plot(kind='bar', title='probability of next word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cabd785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, probs = list(prob_next_word),list(prob_next_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e4998afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scenario'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(words, p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "53e8b5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a no deal brexit'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence += ' ' + np.random.choice(words, p=probs)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6fec6d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a no deal\n",
      "a no deal brexit the tory hardline brexiters are now zipping their lips they have concluded that boris johnson s pledge to make its agreement to any deal which included the controversial northern ireland backstop how to avoid new border checks for eu nationals to enter its territory and claim certain benefits there as swiss nationals can do in his conference speech today with what sounded like envy but it is a coherent and functioning statute book on the eu negotiations before june s summit of eu leaders the eu is always a five past midnight affairs as eurocrats wait until the end of march but mrs may decided for the second day of mr trump were leaked to a newspaper article saying they would prefer no brexit at all the longer the argument plays out the softer the brexit provided britain stays in the single market by remaining in a customs union with the eu was delighted with the agreement and the uk if some of our proposals for a fantastical heath robinson customs arrangement is because theresa may has privately vowed to thwart any attempt to do that they include import tariffs which are taxes applied only to goods traded across\n"
     ]
    }
   ],
   "source": [
    "total_sequence = 'a no deal'\n",
    "print(total_sequence)\n",
    "sequence = total_sequence\n",
    "for _ in range(200):\n",
    "    prob_next_word = Counter({w: tetragram[f'{sequence} {w}'] / trigrams[sequence] for w in vocabulary})\n",
    "    words, probs = list(prob_next_word),list(prob_next_word.values())\n",
    "    total_sequence += ' ' + np.random.choice(words, p=probs)\n",
    "    sequence = ' '.join(total_sequence.split()[-3:])\n",
    "print(total_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1e991",
   "metadata": {},
   "source": [
    "## Predict the next word with gpt-2\n",
    "\n",
    "https://jamesmccaffrey.wordpress.com/2021/10/21/a-predict-next-word-example-using-hugging-face-and-gpt-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9cb34eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "toker = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "71116eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "db19b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"A no deal\"\n",
    "\n",
    "\n",
    "inpts = toker(seq, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5f3b8923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  32,  645, 1730]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e174d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inpts).logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2feb70d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ab7a688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "probabilities = F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d5817bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0731e-03, 3.7448e-03, 1.1571e-05,  ..., 5.9400e-08, 6.4343e-08,\n",
       "         2.9878e-04]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "63aa236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted token ID of next word: \n",
      "13\n"
     ]
    }
   ],
   "source": [
    "pred_id = torch.argmax(logits).item()\n",
    "print(\"\\nPredicted token ID of next word: \")\n",
    "print(pred_id)\n",
    "\n",
    "pred_word = toker.decode(pred_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "06f94417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "print(pred_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb7969",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99a1b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fa213409",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'the duke of'\n",
    "sequence = 'A no deal Brexit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1c5e3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"A no deal Brexit would require further concessions on the EU's terms. In other words, UK citizens would not be given a European passport.\\n\\n\"},\n",
       " {'generated_text': \"A no deal Brexit would not create a 'factory for Brexit', as the EU chief European negotiator has said. It would open the door for negotiations\"},\n",
       " {'generated_text': 'A no deal Brexit could threaten growth of up to 1% for many years.\\n\\nIn an analysis of the report which the government has given to'}]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(sequence, max_length = 30, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "29a1970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(GPT2LMHeadModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f1f5c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fa9ee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GPT2Model.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0a8b72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "31900704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   32,   645,  1730, 11435]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c0fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9c62559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(**tokenizer(sequence, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9659afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 50257])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "09f19573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' would'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(np.argmax(predictions.logits[0,-1,:].detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "43de695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A no deal Brexit would be a disaster for the UK, but for the EU as a whole.\n",
      "\n",
      "\"The UK is a member of the European Union, and we are not going to be able to leave the EU without the EU's help\n"
     ]
    }
   ],
   "source": [
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb138a8d",
   "metadata": {},
   "source": [
    "# Fine-tuning a GPT-2 Model\n",
    "\n",
    "https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd135cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model, AutoModelForCausalLM\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0c6fddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('https://programminghistorian.org/assets/interrogating-national-narrative-gpt/articles.txt'\n",
    "                       ).text.lower().strip().split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "38da8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(text,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "c9639f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "brexit_dataset = Dataset.from_pandas(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c77aa571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                           truncation=True, \n",
    "                                           max_length=768, \n",
    "                                          bos_token='<|startoftext|>', \n",
    "                                          eos_token='<|endoftext|>', \n",
    "                                          pad_token='<|pad|>') #gpt2-medium\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5745ebb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/130566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 130566\n",
       "})"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = brexit_dataset.map(\n",
    "        tokenize_function, batched=True, remove_columns=[\"text\"]\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7717b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117509 13056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 117509\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 13056\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(tokenized_datasets) *.9)\n",
    "test_size = int(len(tokenized_datasets) *.1)\n",
    "print(train_size,test_size)\n",
    "dataset = tokenized_datasets.train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f1279219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "#training_args = TrainingArguments(\"test-trainer\")\n",
    "model_checkpoint = 'gpt-2'\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"gpt-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    #push_to_hub=True,\n",
    "    #fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c1388989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9e709914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='5511' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/5511 00:36 < 27:54:06, 0.05 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [300]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sas-llm/lib/python3.9/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sas-llm/lib/python3.9/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1929\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1932\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1934\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1935\u001b[0m ):\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/sas-llm/lib/python3.9/site-packages/transformers/trainer.py:2717\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2715\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[1;32m   2716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2717\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2719\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/anaconda3/envs/sas-llm/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sas-llm/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad5721",
   "metadata": {},
   "source": [
    "# Few shot leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeed20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69602d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sas-llm",
   "language": "python",
   "name": "sas-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
