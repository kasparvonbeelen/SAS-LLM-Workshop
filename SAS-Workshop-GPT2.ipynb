{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50f7f68",
   "metadata": {},
   "source": [
    "# Pocking at Ever Larger Language Models\n",
    "## An introduction for (digital) humanists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077586e",
   "metadata": {},
   "source": [
    "## Pretrained Language Models\n",
    "\n",
    "- Transition from N-Gram to Neural Language Models\n",
    "\n",
    "- [Don't count, predict!](https://aclanthology.org/P14-1023.pdf) (when training a language models)\n",
    "\n",
    "## Terminology\n",
    "- Paramaters are \"knobs\" you can adjust to get the output you want\n",
    "- Deep Learning algorithms attempt to find the optimal setting of these knobs\n",
    "![simpleNN](https://miro.medium.com/v2/resize:fit:624/1*U3FfvaDbIjr7VobJj89fCQ.png)\n",
    "\n",
    "- LM pretraining and fine-tuning (Why it works better)\n",
    "\n",
    "## Common PLM variants\n",
    "- Causal/Autoregressive language models (GPT series)\n",
    "- Masked Language Models (BERT and family)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee98c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25bb7969",
   "metadata": {},
   "source": [
    "## Text Generation with GPT-2\n",
    "\n",
    "While more complex, GPT-2 does essentially the same as our simple N-Gram LM.\n",
    "- Given a prompt, it computes the probability of the next word\n",
    "- Then we sample a word, add it to prompt and repeat!\n",
    "\n",
    "Materials are inspired on this [Blog Post](https://huggingface.co/blog/how-to-generate) and the excellent programming historian post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068fc31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (4.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: filelock in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kasparbeelen/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa213409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence = 'the duke of'\n",
    "#sequence = 'A no deal Brexit'\n",
    "sequence = 'The UK is'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c5e3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The UK is still grappling with the aftermath of Brexit in a period when millions are left living without the means to support themselves and their children.\"\\n\\n'},\n",
       " {'generated_text': 'The UK is leading the way with free wireless and home wireless. We have some of the best wireless coverage, including the largest networks in the world.'},\n",
       " {'generated_text': 'The UK is no longer able to buy new passports in any area, which means that people can get their British passport through the UK with no hassle.'},\n",
       " {'generated_text': \"The UK is the UK's largest commercial oil producer and its financial sector is the second largest in the world after China, and currently accounts for only 15\"},\n",
       " {'generated_text': \"The UK is the leading producer of global high quality health services and public health services that are designed to tackle the most pressing challenges and to ensure people's\"},\n",
       " {'generated_text': 'The UK is a leading market in the digital space, but as the number of companies offering to invest in the digital space declines, so will the need'},\n",
       " {'generated_text': 'The UK is the biggest export market of the world thanks to its high-technology and high-skill sector and its long-term commitment to develop opportunities'},\n",
       " {'generated_text': 'The UK is still facing a huge problem with its housing market and its finances because the country has no money to invest in housing, so there is no'},\n",
       " {'generated_text': 'The UK is expected to pay £9.4bn a year to support the NHS as it seeks to invest in its own health service, a figure'},\n",
       " {'generated_text': 'The UK is now the European trading partner after the EU took over.\\n\\nBritain is now the international primary place where traders like China, Russia and'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(sequence, max_length = 30, num_return_sequences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5e47513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The UK is a member of the European Union as it is outside it.\\nWhen Parliament takes the final vote on a transition deal, if a majority'},\n",
       " {'generated_text': 'The UK is due to leave the EU on 29 March 2019. It will have a very narrow role in EU affairs – but also have a significant role'},\n",
       " {'generated_text': 'The UK is set to leave the European Economic Area in March 2019.\\nThe EU has said it wants the UK to leave the bloc on 29 March'},\n",
       " {'generated_text': 'The UK is committed to having a long and prosperous post-Brexit relationship and the Government’s focus should be on our common interests in trade,'},\n",
       " {'generated_text': 'The UK is prepared to consider “alternative arrangements” to avoid a hard border on the island of Ireland. However, this would create uncertainty'},\n",
       " {'generated_text': 'The UK is due to leave the EU on March 29 and Mr Johnson is set to announce the terms and conditions of Brexit on Tuesday in an unprecedented address'},\n",
       " {'generated_text': \"The UK is already in a customs dispute with the EU over the Irish border. The UK's customs commissioner, Robert Gooding-Harris, says Britain\"},\n",
       " {'generated_text': 'The UK is scheduled to leave the EU on 31 October and Theresa May has been warning politicians in the run-up to the EU summit that she must'},\n",
       " {'generated_text': 'The UK is looking to the EU27 for more clarity on how it plans to leave the customs union.\\nThe Northern Ireland Secretary has insisted the prime'},\n",
       " {'generated_text': 'The UK is set to leave the European Union by 29 March 2019. With no deal or a transition agreement, and to allow us to stay in the'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model = 'Kaspar/gpt-brexit',tokenizer='gpt2')\n",
    "generator(sequence, max_length = 30, num_return_sequences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f52b23",
   "metadata": {},
   "source": [
    "## Behind the pipeline: Next word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1f5c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa9ee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GPT2Model.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a8b72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31900704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 464, 3482,  318]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c62559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(**tokenizer(sequence, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9659afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 50257])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09f19573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(np.argmax(predictions.logits[0,-1,:].detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad5721",
   "metadata": {},
   "source": [
    "# Bias and Toxicity in PLM (and LLMs)\n",
    "\n",
    "An excellent [HuggingFace tutorial](https://colab.research.google.com/drive/1-HDJUcPMKEF-E7Hapih0OmA1xTW2hdAv#scrollTo=MOsHUjgdIrIW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sas-llm",
   "language": "python",
   "name": "sas-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
