{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c6df9c",
   "metadata": {},
   "source": [
    "# 0. Poking at Ever Larger Language Models\n",
    "## An introduction for (digital) humanists\n",
    "\n",
    "### Introduction (5 minutes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3761e5",
   "metadata": {},
   "source": [
    "### Welcome!\n",
    "\n",
    "![Welcome](https://media.giphy.com/media/pNiDRNtb9yWdi/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2fd68e",
   "metadata": {},
   "source": [
    "## Expectation management\n",
    "- In this Taster Session we hope to tickle your **curiosity** regarding language models\n",
    "- At the same time, I am trying out some new materials (which reflect my learning process)\n",
    "> When one Teaches, Two Learn (Robert Heinlein, appeared in an email footer from someone I can not remember).\n",
    "\n",
    "If things sound confusing, they probably still are. In other words, some patience and positive feedback are very appreciated ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d89a54",
   "metadata": {},
   "source": [
    "## \"Ever-Larger\" Language Models\n",
    "\n",
    "![meme](https://preview.redd.it/no-regrets-v0-adjz43rz5zaa1.jpg?auto=webp&s=24821dee00ea212e282ed3668a4d00ba0b686869)\n",
    "- We'll get to ChatGPT (and Large Language Models more generally) but...\n",
    "- I want to paint a wider historical picture.\n",
    "    - Understand recent advances in the history of language models\n",
    "    - Statistical language models (N-Gram models)\n",
    "    - ~~Neural Language Models (word2vec, GloVe, ca. 2013)~~\n",
    "    - Pretrained Langauge Models (ULMFit, ELMO, BERT, GPT-2, ca. 2018)\n",
    "    - Large Language Models (GPT-3, PALM etc, ca. 2020)\n",
    "- Code and programmatic access to language models\n",
    "    - Notebooks with Python code...\n",
    "    - ...but not a taster session about Python\n",
    "- Perspective of Historian/DH researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354934d9",
   "metadata": {},
   "source": [
    "### Rule No. 1: Newest ≠ Bestest!!!\n",
    "\n",
    "- Different language models have different capabilities.\n",
    "- Apply Occam's razor to model parameters. Do I need 175 billion parameters for my research?\n",
    "- Fight Technological Amnesia! Simpler N-Gram models might still be interesting! It all depends on what it is you want to find out...\n",
    "\n",
    "![amnesia](https://www.digitalmomblog.com/wp-content/uploads/2011/10/the-cassette-tape-and-the-pencil.jpg.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2027c02",
   "metadata": {},
   "source": [
    "### Rule No. 2: Ask not what your ~~country~~ model can do for you - ask what you can do for your  ~~country~~ model \n",
    "\n",
    "- Research within AI/Natural Language Processing often emphasizes generalizability (a model needs to work in many different contexts)\n",
    "- DH Research = the process of making technology work for your research.\n",
    "- Easier to adapt simpler technologies to your research questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272992d",
   "metadata": {},
   "source": [
    "### But equally...\n",
    "\n",
    "Ask not what you can do for your model - ask what your model can do for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb298d",
   "metadata": {},
   "source": [
    "Ideas for more rules welcome ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed4c6f",
   "metadata": {},
   "source": [
    "# What's Next\n",
    "- 90s flashback, N-Gram language model (15 minutes)\n",
    "    - understand the basic terminology and principles of language modelling\n",
    "- Sesame Street series of Pretrained Language Models (10 minutes):\n",
    "    - generating text and more with GPT-2\n",
    "- Finally, \"Large\" Language Models (whatever time is left)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb23a1",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c362c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
