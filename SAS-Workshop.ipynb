{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50f7f68",
   "metadata": {},
   "source": [
    "# Pocking at Ever Larger Language Models\n",
    "## An introduction for (digital) humanists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f8ef1",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9047ad",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O animacy.zip https://bl.iro.bl.uk/downloads/59a8c52f-e0a5-4432-9897-0db8c067627c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01edb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip animacy.zip -d animacy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd4cdf",
   "metadata": {},
   "source": [
    "## From mini to somewhat larger\n",
    "\n",
    "... but not large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1d8f8",
   "metadata": {},
   "source": [
    "### A Shakespeare language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ad00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd11e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c975a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('https://www.gutenberg.org/cache/epub/100/pg100.txt').text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62391272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffthe project gutenberg ebook of the complete works of william shakespeare, by william shakespeare\\r\\n\\r'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb8c1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('\\w+')\n",
    "tokens = pattern.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "841f0a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'complete', 'works', 'of', 'william', 'shakespeare', 'by', 'william', 'shakespeare', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'united', 'states', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc90475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04a8e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(tokens: list,n: int=2):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        text\n",
    "        n\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens))]\n",
    "\n",
    "bigrams = ngrams(tokens,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "624c8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project',\n",
       " 'project gutenberg',\n",
       " 'gutenberg ebook',\n",
       " 'ebook of',\n",
       " 'of the',\n",
       " 'the complete',\n",
       " 'complete works',\n",
       " 'works of',\n",
       " 'of william',\n",
       " 'william shakespeare']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf202708",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76cbdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = Counter(ngrams(tokens,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42e5f026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_exeunt _ scene', 320),\n",
       " ('i pray you', 252),\n",
       " ('a room in', 245),\n",
       " ('i will not', 229),\n",
       " ('room in the', 174),\n",
       " ('i know not', 171),\n",
       " ('i do not', 160),\n",
       " ('the duke of', 157),\n",
       " ('i am a', 149),\n",
       " ('the king s', 148)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3170630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tetragram = Counter(ngrams(tokens,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b57f90a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a room in the', 151),\n",
       " ('another part of the', 109),\n",
       " ('_exeunt _ scene ii', 92),\n",
       " ('what s the matter', 77),\n",
       " ('_exeunt _ scene iii', 76),\n",
       " ('room in the palace', 69),\n",
       " ('act iv scene i', 63),\n",
       " ('act iii scene i', 62),\n",
       " ('act v scene i', 62),\n",
       " ('act i scene i', 60)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tetragram.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37ee74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26984"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(tokens)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62c445d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'the duke of'\n",
    "prob_next_word = Counter({w: tetragram[f'{sequence} {w}'] / trigrams[sequence] for w in vocabulary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df091a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('york', 0.2229299363057325),\n",
       " ('norfolk', 0.10828025477707007),\n",
       " ('suffolk', 0.08917197452229299),\n",
       " ('gloucester', 0.08917197452229299),\n",
       " ('buckingham', 0.07006369426751592),\n",
       " ('albany', 0.050955414012738856),\n",
       " ('somerset', 0.044585987261146494),\n",
       " ('exeter', 0.044585987261146494),\n",
       " ('burgundy', 0.03821656050955414),\n",
       " ('lancaster', 0.03184713375796178),\n",
       " ('florence', 0.03184713375796178),\n",
       " ('cornwall', 0.03184713375796178),\n",
       " ('clarence', 0.025477707006369428),\n",
       " ('hereford', 0.025477707006369428),\n",
       " ('milan', 0.01910828025477707),\n",
       " ('bedford', 0.012738853503184714),\n",
       " ('orleans', 0.012738853503184714),\n",
       " ('aumerle', 0.006369426751592357),\n",
       " ('venice', 0.006369426751592357),\n",
       " ('lorraine', 0.006369426751592357)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_next_word.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cabd785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, probs = list(prob_next_word),list(prob_next_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4998afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'norfolk'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(words, p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53e8b5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the duke of york'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence += ' ' + np.random.choice(words, p=probs)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fec6d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the duke of exeter\n",
      "the duke of exeter his\n",
      "the duke of exeter his brother\n",
      "the duke of exeter his brother archbishop\n",
      "the duke of exeter his brother archbishop late\n",
      "the duke of exeter his brother archbishop late of\n",
      "the duke of exeter his brother archbishop late of canterbury\n",
      "the duke of exeter his brother archbishop late of canterbury sir\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good old\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good old commander\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good old commander and\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good old commander and a\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good old commander and a most\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good old commander and a most kind\n",
      "the duke of exeter his brother archbishop late of canterbury sir thomas erpingham williams a good old commander and a most kind gentleman\n"
     ]
    }
   ],
   "source": [
    "total_sequence = 'the duke of'\n",
    "sequence = total_sequence\n",
    "for _ in range(20):\n",
    "    prob_next_word = Counter({w: tetragram[f'{sequence} {w}'] / trigrams[sequence] for w in vocabulary})\n",
    "    words, probs = list(prob_next_word),list(prob_next_word.values())\n",
    "    total_sequence += ' ' + np.random.choice(words, p=probs)\n",
    "    sequence = ' '.join(total_sequence.split()[-3:])\n",
    "    print(total_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43504f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (4.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/sas-llm/lib/python3.9/site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa213409",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'the duke of'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c5e3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'the duke of Jersey with its royal and military background and its history as a leader of modern civilised and democratic society.\\n\\nIn March 2015'},\n",
       " {'generated_text': 'the duke of York\" is the president of the United States.\\n\\nDuke of York is one of the most prestigious hereditary monarchy in the'},\n",
       " {'generated_text': 'the duke of Naples – that was a real good decision.\"\\n\\nBut the case goes deeper. It also raises serious questions concerning the effectiveness or'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(sequence, max_length = 30, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99a1b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1f5c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a8b72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31900704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1169,  288, 4649,  286]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43de695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "the duke of York, who was a member of the royal family, was a member of the royal family, and was a member of the royal family.\n",
      "\n",
      "The Duke of York was a member of the royal family, and was a member\n"
     ]
    }
   ],
   "source": [
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa164d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sas-llm",
   "language": "python",
   "name": "sas-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
