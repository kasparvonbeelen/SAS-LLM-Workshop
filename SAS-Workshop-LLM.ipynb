{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a57bea1",
   "metadata": {},
   "source": [
    "# Scaling UP: Large Language Models\n",
    "\n",
    "\n",
    "Finally! Let's turn to the more recent events, the advent of Large Language Models (LLMs).\n",
    "\n",
    "![finally](https://media.giphy.com/media/hZj44bR9FVI3K/giphy.gif)\n",
    "\n",
    "Most the materials in this Notebook based on:\n",
    "- A recent [survey article](https://arxiv.org/abs/2303.18223) on Large Language Models\n",
    "- The [Stanford Course CS324](https://stanford-cs324.github.io/winter2023/assignment/) on Advances in Foundation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0c465",
   "metadata": {},
   "source": [
    "## Focus \n",
    "- Context, large, larger, largest? (Theory)\n",
    "- Accessing LLMs (Practical)\n",
    "- Interacting with LLMs (Practical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444c99a",
   "metadata": {},
   "source": [
    "## Large Language Models\n",
    "- Scaling pretrained language models improves performance*\n",
    "- Scaling refers to increasing model size, data and compute \n",
    " \n",
    "![model_size](https://s10251.pcdn.co/wp-content/uploads/2023/03/2023-Alan-D-Thompson-AI-Bubbles-Rev-7b.png)\n",
    "\n",
    "\n",
    "*performance on tasks the ML/NLP cares about (\"benchmarking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5680d2",
   "metadata": {},
   "source": [
    "### Scaling leads to qualitatively different (i.e. better?) models\n",
    "\n",
    "Three differences between PLMs and LLMs (from the survey paper):\n",
    "- LLMs **might** display emergent abilities that are not observed in smaller PLMs.\n",
    "- LLMs would revolutionize the way we use AI algorithms: prompting, i.e. formulate a task so that LLMs can \"understand\" or at least follow\n",
    "- \"Development of LLMs no longer draws a clear distinction between research and engineering.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d754a",
   "metadata": {},
   "source": [
    "### LLMs are general-purpose language task solvers\n",
    "\n",
    "- Imagine you want to automatically classify documents, by genre, emotion, topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605ba90",
   "metadata": {},
   "source": [
    "\n",
    "- PLM vs LLM: What does \"Large\" mean?\n",
    "- Are LLMs qualitatively different than PLMs\n",
    "- Different capabilities\n",
    "    - Traditionally: learn from examples\n",
    "        - adapt a model to a set of examples (training/fine-tuning)\n",
    "    - No adaptation needed, prompting instead if traing\n",
    "        - In context learning\n",
    "        - Zero and few-shot \n",
    "        - Chain of thought reasoning\n",
    "- \"Emerging\" Capabilities\n",
    "    - Ideological dimensions behind the AI discourse\n",
    "\n",
    "- Programmatic Access to LLMs\n",
    "\n",
    "- Using LLMs: from checkpoints or via API\n",
    "    - open and closed, [paper](https://www.nature.com/articles/d41586-023-01295-4)\n",
    "        - risks\n",
    "    - hard to say which will turn out to b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Critique of LLMs\n",
    "Stochastic Parrots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379c2be",
   "metadata": {},
   "source": [
    "# Checkpoint: Hugging Face and BLOOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57204c30",
   "metadata": {},
   "source": [
    "Introduction to BLOOM. Based on Stanford Course\n",
    "https://colab.research.google.com/drive/13gyUcsX7KtkwSJ1PfW8MrlXQePVD_jFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670233e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch datasets  accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17321550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97daf7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"bigscience/bloom-1b7\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2d353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a zero-shot prompt\n",
    "sample_review = 'I really love this movie'\n",
    "prompt = f\"\"\"Classify the following movie review as positive or negative\n",
    "\n",
    "Review: {sample_review}\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed prompt to model to generate an output\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "output = generator(prompt, max_new_tokens=20)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc97abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Write a few-shot prompt. Here we include a few in-context examples to the model \n",
    "demonstrating how to complete the tasks\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Review: The movie was horrible\n",
    "Sentiment: Negative\n",
    "\n",
    "Review: The movie was the best movie I have watched all year!!!\n",
    "Sentiment: Positive\n",
    "\n",
    "Review: {sample_review}\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed prompt to model to generate an output\n",
    "output = generator(prompt, max_new_tokens=1)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://bl.iro.bl.uk/downloads/59a8c52f-e0a5-4432-9897-0db8c067627c?locale=en -O animacy.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24694838",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "unzip animacy.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/LwM-nlp-animacy-annotations-machines19thC.tsv', index_col=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.animacy==0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88016ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.animacy==0) & (df.TargetExpression=='machine') ].head(10).Sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.animacy==1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e62cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.animacy==1].head(3).Sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b64fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentence = \"When the ***machine*** has been let down into the sea, and the coral is thought sufficiently\"\n",
    "prompt = f\"\"\"We want to know if the word ***machine*** in the following sentences is animate.\n",
    "With animacy we mean the property of being alive\n",
    "\n",
    "Sentence: Immured in a convent, debarred from life-giving air and light, and the beauty of life, we cease to be living, feeling, thinking girls and women, we become mere ***machines*** who blindly obey the head that directs us.'\n",
    "Animacy: Animate\n",
    "\n",
    "Sentence: Now that we were free from all fear of encountering bad cha racters in the house, the boom-boom of the little man's big voice went on unintermittingly, like a ***machine*** at work in the neigh bourhood\n",
    "Animacy: Animate\n",
    "\n",
    "Sentence: He led his ***machine*** to the side of thi_ footpath. \n",
    "Animacy: Inanimante\n",
    "\n",
    "Sentence: The drawing shows the ***machine*** ready to begin its forward stroke.'\n",
    "Animacy: Inanimante\n",
    "\n",
    "Sentence: {target_sentence}\n",
    "Animacy: \n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed421ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed prompt to model to generate an output\n",
    "output = generator(prompt, max_new_tokens=2)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dacc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[[\"Sentence\",'animacy']].sample(10).replace({\"animacy\":{1: 'Animate',0: 'Inanimate'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c271b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template(target_sentence):\n",
    "    return f\"\"\"We want to know if the word ***machine*** in the following sentences is animate.\n",
    "    With animacy we mean the property of being alive\n",
    "\n",
    "    Sentence: Immured in a convent, debarred from life-giving air and light, and the beauty of life, we cease to be living, feeling, thinking girls and women, we become mere ***machines*** who blindly obey the head that directs us.'\n",
    "    Animacy: Animate\n",
    "\n",
    "    Sentence: Now that we were free from all fear of encountering bad cha racters in the house, the boom-boom of the little man's big voice went on unintermittingly, like a ***machine*** at work in the neigh bourhood\n",
    "    Animacy: Animate\n",
    "\n",
    "    Sentence: He led his ***machine*** to the side of thi_ footpath. \n",
    "    Animacy: Inanimante\n",
    "\n",
    "    Sentence: The drawing shows the ***machine*** ready to begin its forward stroke.'\n",
    "    Animacy: Inanimante\n",
    "    \n",
    "    Sentence: {target_sentence}\n",
    "    Animacy: \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f049874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23528, 9)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = pd.read_csv('../data/emotion.csv')\n",
    "headlines = headlines[headlines.apply(lambda x : len(str(x.sentence)) >= 10, axis=1)]\n",
    "headlines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4c9a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT ON LEPROSY.\n",
      "ROMAN REMAINS AT CHESTER.\n",
      "_ . LATE STRIKE OR LOOK-OUT OF LONDON TAILORS.\n",
      "LIGHT CAVALRY CHARGE AT BALACLA.VA.\n",
      "SHIP-JOINERS LOCK-OUT ON TaL\n",
      "CO-OPERATIV:\n",
      "PA U.P.E RISli AND CRIME.\n",
      "FOREIGN TELEGRAMS. FRANCE AND AMERICA.\n",
      "VISIT TO DAHOMEY.\n",
      "DENMARK AND PRUSSIA.\n",
      "DENMARK AND PRUSSIA.\n",
      "R.EGISTERED POR TRANSMISSION ABROAD\n",
      "T INTELLIU-E N CE.\n",
      "EDI/VP. GROVE,\n",
      "C ii_RISTMAS ENTE RT MENTS\n",
      "VISIT OF GARIBALDI.\n",
      "CAPE MAIL.\n",
      "CAPE MAIL.\n",
      "CAPE MAIL.\n",
      "VISIT TO CHISWICK.\n",
      "ARBITRITION AT •HUDDERSIFIELD.\n",
      "MR. ERNEST JONES ON DENIOCRA.CY.\n",
      "MAYOR OF BELFAST.\n",
      "\"HALF CLEAR BEN EFIT P\"\n",
      "AUSTRIA AND PRUSSIA.\n",
      "AUSTRIA AND PRUSSIA.\n",
      "AUSTRIA AND PRUSSIA.\n",
      "AUSTRIA AND PRUSSIA.\n",
      "RUSSIA. AND AUSTRIA.\n",
      "CYCLONE AT CALCUTTA.\n",
      "LATER FROX\n",
      "PLATE ROBBERY AT HAMPSTEAD.\n",
      "LIST OF PRICES.\n",
      "MR. GOLDWIN SMITH ON CANADA.\n",
      "VISIT TO DR. STIORTHOUSE.\n",
      "MR. BRIGHT, M.P., ON REFORM.\n",
      "PRUSSIA AND DENMARK.\n",
      "1.4 ICOD REFORMATION NECESS ARY.\n",
      "ROYAL -UNITED SERVICE INSTITUTION.\n",
      "CALCUTTA AND CHINA MAILS\n",
      "LONDON ILLRKETS.\n",
      "Tlig CAPE MAIL.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "READ THE NEW MEDICAL GUIDE.\n",
      "ETNA AWARE:.\n",
      "ODDFELLOWS (MANCHESTER UNITY).\n",
      "'PROPOSED AMERICAN VISIT.\n",
      "_YR. COBDEN ON TIIE HOSTILITIES IN JAPAN.\n",
      "PLAIN DEALER,\n",
      "ADDRESS TO TM IFORKMEA\n",
      "READ TIII NEW MEDRIAL GUIDE.\n",
      "EAST-END COOPERS\n",
      "EAST LONDON WORKING CLASSES EXHIBITS ON.\n",
      "MR. GOLDIVIN SMITE ON CANADA.\n",
      "CURRENT PRICES.\n",
      "CURRENT PRICES.\n",
      "CURRENT PRICES.\n",
      "CURRENT PRICES.\n",
      "BRITISH AMALGAMATED SOCIETY OF BASKET MAKERS:\n",
      "MR. GLADSTONE AND SOUTH LANCASHIRE.\n",
      "AUSTRIA AND lIUNGARY\n",
      "CO-OPERATIVE 1 N TELLIGEN CE.\n",
      "\"FLINT JACK.\"\n",
      "POLAN.D AND RUSSIA.\n",
      "MENT. LONDON CARPENTERS AND JOINERS.\n",
      "REPORT ON THE ADDRESS.\n",
      "13‘TMOP AND THE CANNIBALS.\n",
      "AUSTRIA AND RUSSIA.\n",
      "LIST OF MEN LEFT BEHIND AT SYDNEY.\n",
      "PROPERTY IN LAND, MINES, RAILROADS, &C.\n",
      "HOUSE OF LORDS. TEIURSDAY.\n",
      "1N RR YARNCILD.\n",
      "HOW MAYOR TAIT, OF LIMERICK, GOT\n",
      "MR. RITSKIN ON STRIKES AND – ARBITRATION.\n",
      "OTAGO LINE.\n",
      "VISIT OF .N.EZsZfjEuIANDERB TO\n",
      "PRICES OF CHEESE, HAMS, &o.\n",
      "MINISTERIAL MIDNIGHT VISIT.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "PRICES OF LEATHER AT LEADENHALL.\n",
      "MB. DISRAELI UPON CHU RUII. AND STATE.\n",
      "ALBERT MEMORIAL AT HALIFAX.\n",
      "LATER FROM AMERICA,\n",
      "LATER FROM AMERICA,\n",
      "tYMNIBITS ACCIOENT TINT LONDON.\n",
      "_RUSSIA'S WAR PREPARATIONS.\n"
     ]
    }
   ],
   "source": [
    "top_n = 100\n",
    "print('\\n'.join(headlines.sort_values('neutral', ascending=False)[:top_n].sentence.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57c873",
   "metadata": {},
   "source": [
    "# API: Accessing OpenAI's GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e368e",
   "metadata": {},
   "source": [
    "Full documentation is available [here](https://platform.openai.com/docs/api-reference/completions/create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hey ChatGPT how can I ask a question to\n",
    "import openai\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = 'YOUR_API_KEY'\n",
    "\n",
    "# Define the function to ask a question\n",
    "def ask_question(question):\n",
    "    prompt = f\"Question: {question}\\nAnswer:\"\n",
    "\n",
    "    # Generate a response from ChatGPT\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003', # Select the model you want to use\n",
    "        prompt=prompt,  # Your query as a prompt\n",
    "        max_tokens=50,  # Adjust the max tokens according to your needs\n",
    "        n=1, # Number of completions to generate\n",
    "        stop=None, # \n",
    "        temperature=0.7 # Regulate the LLM creativity. Lower values will produce more similar responses\n",
    "    )\n",
    "\n",
    "    # Extract and return the answer from the response\n",
    "    answer = response.choices[0].text.strip().split('\\n')[0]\n",
    "    return answer\n",
    "\n",
    "# Ask a question to ChatGPT\n",
    "question = \"What is the capital of France?\"\n",
    "answer = ask_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4dd9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-4.9.2.tar.gz (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: lxml\n",
      "  Building wheel for lxml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lxml: filename=lxml-4.9.2-cp39-cp39-macosx_11_0_arm64.whl size=1567555 sha256=538f09138c1a799b3780432b7eb024d42ede7914498fa1c8278762f01d3eabb7\n",
      "  Stored in directory: /Users/kasparbeelen/Library/Caches/pip/wheels/74/7c/5a/e117656a962a1a15a3d2ac1bde4bc6193d62dc5d7e9c51e15e\n",
      "Successfully built lxml\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e7cd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "\n",
    "from pathlib import Path\n",
    "xml_files = Path('../data/0002247').glob('**/*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8704a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "def get_title(path):\n",
    "    try:\n",
    "        with open(path,'rb') as xml:\n",
    "            tree = etree.parse(xml)\n",
    "        return tree.xpath('//item/title')[0].text\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0463c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(map(get_title,xml_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "217ef8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOTICE TO CORRESPONDENTS,',\n",
       " 'POLICE INTELLIGENCE.',\n",
       " 'NAVAL AND MILITARY.',\n",
       " 'WANDSWORTH.',\n",
       " 'BRITISH MUSEUM',\n",
       " \"PROCLAMATION OF THE DANISH COMMANDER4N;C'HIEF. '\",\n",
       " 'DEATH FROM DESTITUTION.',\n",
       " None,\n",
       " 'MEXICO.',\n",
       " 'FOREIGN TELEGRAMS.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3474bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [t for t in titles if t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff6b9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n'.join([t.strip() for t in titles])\n",
    "with open('../data/0002247_titles.txt','w') as out_text:\n",
    "    out_text.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46ef65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sas-llm",
   "language": "python",
   "name": "sas-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
